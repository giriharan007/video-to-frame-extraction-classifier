{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = \"D:\\Projects\\deepfake detection project\\deepfake detection\\Real\"\n",
    "fake_dir =\"D:\\Projects\\deepfake detection project\\deepfake detection\\Fake\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_dir, image_dir):\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    for video in os.listdir(video_dir):\n",
    "        cap = cv2.VideoCapture(os.path.join(video_dir, video))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_index = np.random.randint(0, frame_count)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            video_name = os.path.splitext(video)[0]\n",
    "            image_name = video_name + \"_\" + str(frame_index) + \".jpg\"\n",
    "            cv2.imwrite(os.path.join(image_dir, image_name), frame)\n",
    "        cap.release()\n",
    "\n",
    "extract_frames(real_dir, \"D:\\deepfake detection project\\deepfake detection/real_ph\")\n",
    "extract_frames(fake_dir, \"D:\\deepfake detection project\\deepfake detection/fake_ph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dirs, labels):\n",
    "    images = []\n",
    "    image_labels = []\n",
    "    for image_dir, label in zip(image_dirs, labels):\n",
    "        for image in os.listdir(image_dir):\n",
    "            img = cv2.imread(os.path.join(image_dir, image))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img / 255.0 \n",
    "            images.append(img)\n",
    "            image_labels.append(label)\n",
    "            break\n",
    "    images = np.array(images)\n",
    "    image_labels = np.array(image_labels)\n",
    "    return images, image_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data([\"D:\\deepfake detection project\\deepfake detection/real_ph\",\"D:\\deepfake detection project\\deepfake detection/fake_ph\" ], [0, 1])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.1, callbacks=[checkpoint])\n",
    "model.evaluate(X_test, y_test)\n",
    "model.load_weights(\"best_model.h5\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_modelv1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
